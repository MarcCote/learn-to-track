#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os

# # Hack so you don't have to put the library containing this script in the PYTHONPATH.
# sys.path = [os.path.abspath(os.path.join(__file__, '..', '..'))] + sys.path

from os.path import join as pjoin
import argparse

from smartlearner import views
from smartlearner.status import Status
from smartlearner import utils as smartutils

from learn2track.utils import Timer
from learn2track.factories import loss_factory, batch_scheduler_factory

from learn2track import datasets
from learn2track.neurotools import VolumeManager


def build_parser():
    description = "Report the reconstruction error of a GRU model on a dataset of streamlines coordinates and DWIs."
    p = argparse.ArgumentParser(description=description)

    # General options (optional)
    p.add_argument('name', type=str, help='name/path of the experiment.')
    p.add_argument('--subjects', nargs='+', required=True, help='file containing validation data (as generated by `process_streamlines.py`).')
    p.add_argument('--dataset-name', default="validset", help='name to use when saving the results. Default: %(default)s')
    p.add_argument('--batch_size', type=int, default=100, help='size of the batch.')

    loss_type = p.add_mutually_exclusive_group(required=False)
    loss_type.add_argument('--expected-value', action='store_const', dest='loss_type', const='expected_value',
                           help='Use timestep expected value L2 error to color streamlines')
    loss_type.add_argument('--maximum-component', action='store_const', dest='loss_type', const='maximum_component',
                           help='Use timestep maximum distribution component L2 error to color streamlines')

    p.add_argument('-f', '--force', action='store_true', help='restart training from scratch instead of resuming.')
    return p


def main():
    parser = build_parser()
    args = parser.parse_args()
    print(args)

    # Get experiment folder
    experiment_path = args.name
    if not os.path.isdir(experiment_path):
        # If not a directory, it must be the name of the experiment.
        experiment_path = pjoin(".", "experiments", args.name)

    if not os.path.isdir(experiment_path):
        parser.error('Cannot find experiment: {0}!'.format(args.name))

    # Load experiments hyperparameters
    try:
        hyperparams = smartutils.load_dict_from_json_file(pjoin(experiment_path, "hyperparams.json"))
    except FileNotFoundError:
        hyperparams = smartutils.load_dict_from_json_file(pjoin(experiment_path, "..", "hyperparams.json"))

    # Use this for hyperparams added in a new version, but nonexistent from older versions
    retrocompatibility_defaults = {'feed_previous_direction': False,
                                   'predict_offset': False,
                                   'normalize': False,
                                   'keep_step_size': False,
                                   'sort_streamlines': False,
                                   'use_layer_normalization': False,
                                   'drop_prob': 0.,
                                   'use_zoneout': False}
    for new_hyperparams, default_value in retrocompatibility_defaults.items():
        if new_hyperparams not in hyperparams:
            hyperparams[new_hyperparams] = default_value

    with Timer("Loading dataset", newline=True):
        volume_manager = VolumeManager()
        dataset = datasets.load_tractography_dataset(args.subjects, volume_manager, name="dataset", use_sh_coeffs=hyperparams['use_sh_coeffs'])
        print("Dataset size:", len(dataset))

    with Timer("Loading model"):
        model = None
        if hyperparams['model'] == 'gru_regression':
            from learn2track.models import GRU_Regression
            model = GRU_Regression.create(experiment_path, volume_manager=volume_manager)
        elif hyperparams['model'] == 'gru_mixture':
            from learn2track.models import GRU_Mixture
            model = GRU_Mixture.create(experiment_path, volume_manager=volume_manager)
        elif hyperparams['model'] == 'gru_multistep':
            from learn2track.models import GRU_Multistep_Gaussian
            model = GRU_Multistep_Gaussian.create(experiment_path, volume_manager=volume_manager)
            model.k = 1
            model.m = 1
        elif hyperparams['model'] == 'ffnn_regression':
            from learn2track.models import FFNN_Regression
            model = FFNN_Regression.create(experiment_path, volume_manager=volume_manager)
        else:
            raise NameError("Unknown model: {}".format(hyperparams['model']))
        model.drop_prob = 0.  # Make sure dropout/zoneout is not used when testing

    with Timer("Building evaluation function"):
        # Override K for gru_multistep
        if 'k' in hyperparams:
            hyperparams['k'] = 1

        batch_scheduler = batch_scheduler_factory(hyperparams, dataset, train_mode=False, batch_size_override=args.batch_size)
        loss = loss_factory(hyperparams, model, dataset, loss_type=args.loss_type)
        l2_error = views.LossView(loss=loss, batch_scheduler=batch_scheduler)

    with Timer("Evaluating...", newline=True):
        results_file = pjoin(experiment_path, "results.json")
        results = {}
        if os.path.isfile(results_file) and not args.force:
            print("Loading saved results... (use --force to re-run evaluation)")
            results = smartutils.load_dict_from_json_file(results_file)

        tag = ""
        if args.loss_type == 'expected_value' or hyperparams['model'] == 'gru_regression':
            tag = "_EV_L2_error"
        elif args.loss_type == 'maximum_component':
            tag = "_MC_L2_error"
        elif hyperparams['model'] == 'gru_mixture' or hyperparams['model'] == 'gru_multistep':
            tag = "_NLL"

        entry = args.dataset_name + tag

        if entry not in results or args.force:
            with Timer("Evaluating {}".format(entry)):
                dummy_status = Status()  # Forces recomputing results
                results[entry] = {'mean': float(l2_error.mean.view(dummy_status)), 'stderror': float(l2_error.stderror.view(dummy_status))}
                smartutils.save_dict_to_json_file(results_file, results)  # Update results file.

        print("{}: {:.4f} Â± {:.4f}".format(entry, results[entry]['mean'], results[entry]['stderror']))


if __name__ == "__main__":
    main()
